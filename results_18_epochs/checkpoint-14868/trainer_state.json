{
  "best_metric": 0.7025751072961374,
  "best_model_checkpoint": "./results/checkpoint-13216",
  "epoch": 18.0,
  "eval_steps": 500,
  "global_step": 14868,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12106537530266344,
      "grad_norm": 2.765415906906128,
      "learning_rate": 1.8159806295399517e-06,
      "loss": 1.5554,
      "step": 100
    },
    {
      "epoch": 0.24213075060532688,
      "grad_norm": 3.91019606590271,
      "learning_rate": 3.6319612590799035e-06,
      "loss": 1.5174,
      "step": 200
    },
    {
      "epoch": 0.36319612590799033,
      "grad_norm": 1.8407082557678223,
      "learning_rate": 5.447941888619855e-06,
      "loss": 1.4676,
      "step": 300
    },
    {
      "epoch": 0.48426150121065376,
      "grad_norm": 3.2791078090667725,
      "learning_rate": 7.263922518159807e-06,
      "loss": 1.391,
      "step": 400
    },
    {
      "epoch": 0.6053268765133172,
      "grad_norm": 2.646129846572876,
      "learning_rate": 9.079903147699758e-06,
      "loss": 1.3235,
      "step": 500
    },
    {
      "epoch": 0.7263922518159807,
      "grad_norm": 2.7294747829437256,
      "learning_rate": 1.089588377723971e-05,
      "loss": 1.2517,
      "step": 600
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 8.69786548614502,
      "learning_rate": 1.2711864406779661e-05,
      "loss": 1.1369,
      "step": 700
    },
    {
      "epoch": 0.9685230024213075,
      "grad_norm": 6.462383270263672,
      "learning_rate": 1.4527845036319614e-05,
      "loss": 1.04,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.582832618025751,
      "eval_loss": 0.9453848004341125,
      "eval_runtime": 17.0488,
      "eval_samples_per_second": 136.667,
      "eval_steps_per_second": 8.564,
      "step": 826
    },
    {
      "epoch": 1.089588377723971,
      "grad_norm": 5.220986366271973,
      "learning_rate": 1.6343825665859565e-05,
      "loss": 0.9994,
      "step": 900
    },
    {
      "epoch": 1.2106537530266344,
      "grad_norm": 5.282207012176514,
      "learning_rate": 1.8159806295399516e-05,
      "loss": 0.9224,
      "step": 1000
    },
    {
      "epoch": 1.331719128329298,
      "grad_norm": 2.9855473041534424,
      "learning_rate": 1.9975786924939468e-05,
      "loss": 0.9336,
      "step": 1100
    },
    {
      "epoch": 1.4527845036319613,
      "grad_norm": 5.80541467666626,
      "learning_rate": 2.179176755447942e-05,
      "loss": 0.9128,
      "step": 1200
    },
    {
      "epoch": 1.5738498789346247,
      "grad_norm": 9.750741004943848,
      "learning_rate": 2.360774818401937e-05,
      "loss": 0.8987,
      "step": 1300
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 4.364406585693359,
      "learning_rate": 2.5423728813559322e-05,
      "loss": 0.8681,
      "step": 1400
    },
    {
      "epoch": 1.8159806295399514,
      "grad_norm": 3.1040382385253906,
      "learning_rate": 2.7239709443099276e-05,
      "loss": 0.8516,
      "step": 1500
    },
    {
      "epoch": 1.937046004842615,
      "grad_norm": 4.116393566131592,
      "learning_rate": 2.9055690072639228e-05,
      "loss": 0.8504,
      "step": 1600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6562231759656653,
      "eval_loss": 0.7943065166473389,
      "eval_runtime": 19.5525,
      "eval_samples_per_second": 119.167,
      "eval_steps_per_second": 7.467,
      "step": 1652
    },
    {
      "epoch": 2.0581113801452786,
      "grad_norm": 4.456066131591797,
      "learning_rate": 2.990314769975787e-05,
      "loss": 0.8387,
      "step": 1700
    },
    {
      "epoch": 2.179176755447942,
      "grad_norm": 5.511723041534424,
      "learning_rate": 2.9701372074253432e-05,
      "loss": 0.8183,
      "step": 1800
    },
    {
      "epoch": 2.3002421307506054,
      "grad_norm": 6.358872890472412,
      "learning_rate": 2.9499596448748993e-05,
      "loss": 0.8418,
      "step": 1900
    },
    {
      "epoch": 2.4213075060532687,
      "grad_norm": 6.415706634521484,
      "learning_rate": 2.9297820823244553e-05,
      "loss": 0.8207,
      "step": 2000
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 6.38765287399292,
      "learning_rate": 2.9098062953995158e-05,
      "loss": 0.8451,
      "step": 2100
    },
    {
      "epoch": 2.663438256658596,
      "grad_norm": 6.188004493713379,
      "learning_rate": 2.8896287328490718e-05,
      "loss": 0.8169,
      "step": 2200
    },
    {
      "epoch": 2.7845036319612593,
      "grad_norm": 3.632892608642578,
      "learning_rate": 2.869451170298628e-05,
      "loss": 0.7994,
      "step": 2300
    },
    {
      "epoch": 2.9055690072639226,
      "grad_norm": 3.9943928718566895,
      "learning_rate": 2.8492736077481842e-05,
      "loss": 0.7955,
      "step": 2400
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.6695278969957081,
      "eval_loss": 0.7544490098953247,
      "eval_runtime": 17.6207,
      "eval_samples_per_second": 132.231,
      "eval_steps_per_second": 8.286,
      "step": 2478
    },
    {
      "epoch": 3.026634382566586,
      "grad_norm": 3.191599130630493,
      "learning_rate": 2.8290960451977402e-05,
      "loss": 0.8241,
      "step": 2500
    },
    {
      "epoch": 3.1476997578692494,
      "grad_norm": 4.202141284942627,
      "learning_rate": 2.8089184826472962e-05,
      "loss": 0.797,
      "step": 2600
    },
    {
      "epoch": 3.2687651331719128,
      "grad_norm": 5.3639116287231445,
      "learning_rate": 2.7887409200968522e-05,
      "loss": 0.7562,
      "step": 2700
    },
    {
      "epoch": 3.389830508474576,
      "grad_norm": 6.105249881744385,
      "learning_rate": 2.7685633575464086e-05,
      "loss": 0.7988,
      "step": 2800
    },
    {
      "epoch": 3.5108958837772395,
      "grad_norm": 13.249978065490723,
      "learning_rate": 2.7483857949959643e-05,
      "loss": 0.7944,
      "step": 2900
    },
    {
      "epoch": 3.6319612590799033,
      "grad_norm": 9.551457405090332,
      "learning_rate": 2.7282082324455206e-05,
      "loss": 0.7697,
      "step": 3000
    },
    {
      "epoch": 3.7530266343825667,
      "grad_norm": 3.4960641860961914,
      "learning_rate": 2.708030669895077e-05,
      "loss": 0.787,
      "step": 3100
    },
    {
      "epoch": 3.87409200968523,
      "grad_norm": 4.792860507965088,
      "learning_rate": 2.6878531073446327e-05,
      "loss": 0.781,
      "step": 3200
    },
    {
      "epoch": 3.9951573849878934,
      "grad_norm": 6.217827796936035,
      "learning_rate": 2.667675544794189e-05,
      "loss": 0.8067,
      "step": 3300
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.6725321888412017,
      "eval_loss": 0.7407618165016174,
      "eval_runtime": 18.3031,
      "eval_samples_per_second": 127.301,
      "eval_steps_per_second": 7.977,
      "step": 3304
    },
    {
      "epoch": 4.116222760290557,
      "grad_norm": 5.877163887023926,
      "learning_rate": 2.647497982243745e-05,
      "loss": 0.7586,
      "step": 3400
    },
    {
      "epoch": 4.237288135593221,
      "grad_norm": 7.096935272216797,
      "learning_rate": 2.627320419693301e-05,
      "loss": 0.7699,
      "step": 3500
    },
    {
      "epoch": 4.358353510895884,
      "grad_norm": 6.1610493659973145,
      "learning_rate": 2.607142857142857e-05,
      "loss": 0.7626,
      "step": 3600
    },
    {
      "epoch": 4.479418886198547,
      "grad_norm": 5.720500946044922,
      "learning_rate": 2.586965294592413e-05,
      "loss": 0.7657,
      "step": 3700
    },
    {
      "epoch": 4.600484261501211,
      "grad_norm": 5.731333255767822,
      "learning_rate": 2.5667877320419695e-05,
      "loss": 0.7713,
      "step": 3800
    },
    {
      "epoch": 4.721549636803874,
      "grad_norm": 3.266845941543579,
      "learning_rate": 2.5466101694915255e-05,
      "loss": 0.7899,
      "step": 3900
    },
    {
      "epoch": 4.842615012106537,
      "grad_norm": 3.915724039077759,
      "learning_rate": 2.5264326069410815e-05,
      "loss": 0.7421,
      "step": 4000
    },
    {
      "epoch": 4.963680387409201,
      "grad_norm": 5.793903827667236,
      "learning_rate": 2.506456820016142e-05,
      "loss": 0.7391,
      "step": 4100
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.6793991416309013,
      "eval_loss": 0.7355446815490723,
      "eval_runtime": 19.5374,
      "eval_samples_per_second": 119.259,
      "eval_steps_per_second": 7.473,
      "step": 4130
    },
    {
      "epoch": 5.084745762711864,
      "grad_norm": 5.413862228393555,
      "learning_rate": 2.486279257465698e-05,
      "loss": 0.7569,
      "step": 4200
    },
    {
      "epoch": 5.2058111380145276,
      "grad_norm": 5.452895164489746,
      "learning_rate": 2.4661016949152544e-05,
      "loss": 0.7263,
      "step": 4300
    },
    {
      "epoch": 5.326876513317191,
      "grad_norm": 7.186793327331543,
      "learning_rate": 2.4459241323648104e-05,
      "loss": 0.7373,
      "step": 4400
    },
    {
      "epoch": 5.447941888619855,
      "grad_norm": 8.415151596069336,
      "learning_rate": 2.4257465698143665e-05,
      "loss": 0.7378,
      "step": 4500
    },
    {
      "epoch": 5.5690072639225185,
      "grad_norm": 6.979359149932861,
      "learning_rate": 2.4055690072639228e-05,
      "loss": 0.751,
      "step": 4600
    },
    {
      "epoch": 5.690072639225182,
      "grad_norm": 5.933982849121094,
      "learning_rate": 2.3853914447134785e-05,
      "loss": 0.7569,
      "step": 4700
    },
    {
      "epoch": 5.811138014527845,
      "grad_norm": 6.8947834968566895,
      "learning_rate": 2.365213882163035e-05,
      "loss": 0.7598,
      "step": 4800
    },
    {
      "epoch": 5.932203389830509,
      "grad_norm": 7.2505784034729,
      "learning_rate": 2.345036319612591e-05,
      "loss": 0.776,
      "step": 4900
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.6811158798283262,
      "eval_loss": 0.7302214503288269,
      "eval_runtime": 17.697,
      "eval_samples_per_second": 131.661,
      "eval_steps_per_second": 8.25,
      "step": 4956
    },
    {
      "epoch": 6.053268765133172,
      "grad_norm": 5.811050891876221,
      "learning_rate": 2.324858757062147e-05,
      "loss": 0.7565,
      "step": 5000
    },
    {
      "epoch": 6.174334140435835,
      "grad_norm": 6.254152774810791,
      "learning_rate": 2.3046811945117033e-05,
      "loss": 0.7319,
      "step": 5100
    },
    {
      "epoch": 6.295399515738499,
      "grad_norm": 5.259845733642578,
      "learning_rate": 2.284503631961259e-05,
      "loss": 0.7413,
      "step": 5200
    },
    {
      "epoch": 6.416464891041162,
      "grad_norm": 6.5421528816223145,
      "learning_rate": 2.2643260694108153e-05,
      "loss": 0.7215,
      "step": 5300
    },
    {
      "epoch": 6.5375302663438255,
      "grad_norm": 7.445881366729736,
      "learning_rate": 2.2441485068603713e-05,
      "loss": 0.7128,
      "step": 5400
    },
    {
      "epoch": 6.658595641646489,
      "grad_norm": 5.848901748657227,
      "learning_rate": 2.2239709443099273e-05,
      "loss": 0.7531,
      "step": 5500
    },
    {
      "epoch": 6.779661016949152,
      "grad_norm": 5.101983547210693,
      "learning_rate": 2.2037933817594834e-05,
      "loss": 0.7435,
      "step": 5600
    },
    {
      "epoch": 6.900726392251816,
      "grad_norm": 10.774394035339355,
      "learning_rate": 2.1836158192090397e-05,
      "loss": 0.7342,
      "step": 5700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.6836909871244635,
      "eval_loss": 0.7246212959289551,
      "eval_runtime": 19.2266,
      "eval_samples_per_second": 121.186,
      "eval_steps_per_second": 7.594,
      "step": 5782
    },
    {
      "epoch": 7.021791767554479,
      "grad_norm": 9.903759956359863,
      "learning_rate": 2.1634382566585957e-05,
      "loss": 0.7445,
      "step": 5800
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 10.54883861541748,
      "learning_rate": 2.1432606941081518e-05,
      "loss": 0.7214,
      "step": 5900
    },
    {
      "epoch": 7.263922518159807,
      "grad_norm": 3.9914090633392334,
      "learning_rate": 2.1230831315577078e-05,
      "loss": 0.6932,
      "step": 6000
    },
    {
      "epoch": 7.38498789346247,
      "grad_norm": 8.693697929382324,
      "learning_rate": 2.1031073446327686e-05,
      "loss": 0.7317,
      "step": 6100
    },
    {
      "epoch": 7.506053268765133,
      "grad_norm": 5.9954023361206055,
      "learning_rate": 2.0829297820823243e-05,
      "loss": 0.7309,
      "step": 6200
    },
    {
      "epoch": 7.627118644067797,
      "grad_norm": 6.991477966308594,
      "learning_rate": 2.0627522195318807e-05,
      "loss": 0.7061,
      "step": 6300
    },
    {
      "epoch": 7.74818401937046,
      "grad_norm": 5.382928371429443,
      "learning_rate": 2.0425746569814367e-05,
      "loss": 0.718,
      "step": 6400
    },
    {
      "epoch": 7.8692493946731235,
      "grad_norm": 9.005842208862305,
      "learning_rate": 2.0223970944309927e-05,
      "loss": 0.7402,
      "step": 6500
    },
    {
      "epoch": 7.990314769975787,
      "grad_norm": 4.455560684204102,
      "learning_rate": 2.002219531880549e-05,
      "loss": 0.7423,
      "step": 6600
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.6763948497854078,
      "eval_loss": 0.759669840335846,
      "eval_runtime": 19.2954,
      "eval_samples_per_second": 120.754,
      "eval_steps_per_second": 7.567,
      "step": 6608
    },
    {
      "epoch": 8.111380145278451,
      "grad_norm": 6.033597469329834,
      "learning_rate": 1.9820419693301048e-05,
      "loss": 0.7193,
      "step": 6700
    },
    {
      "epoch": 8.232445520581114,
      "grad_norm": 4.724209308624268,
      "learning_rate": 1.961864406779661e-05,
      "loss": 0.7095,
      "step": 6800
    },
    {
      "epoch": 8.353510895883778,
      "grad_norm": 3.7786149978637695,
      "learning_rate": 1.941686844229217e-05,
      "loss": 0.6978,
      "step": 6900
    },
    {
      "epoch": 8.474576271186441,
      "grad_norm": 7.11638069152832,
      "learning_rate": 1.921509281678773e-05,
      "loss": 0.7272,
      "step": 7000
    },
    {
      "epoch": 8.595641646489105,
      "grad_norm": 6.223270416259766,
      "learning_rate": 1.9015334947538337e-05,
      "loss": 0.7199,
      "step": 7100
    },
    {
      "epoch": 8.716707021791768,
      "grad_norm": 3.756427049636841,
      "learning_rate": 1.88135593220339e-05,
      "loss": 0.72,
      "step": 7200
    },
    {
      "epoch": 8.837772397094431,
      "grad_norm": 6.543879508972168,
      "learning_rate": 1.861178369652946e-05,
      "loss": 0.7188,
      "step": 7300
    },
    {
      "epoch": 8.958837772397095,
      "grad_norm": 6.1386003494262695,
      "learning_rate": 1.841000807102502e-05,
      "loss": 0.7102,
      "step": 7400
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.6866952789699571,
      "eval_loss": 0.7235232591629028,
      "eval_runtime": 19.2635,
      "eval_samples_per_second": 120.954,
      "eval_steps_per_second": 7.579,
      "step": 7434
    },
    {
      "epoch": 9.079903147699758,
      "grad_norm": 5.298494338989258,
      "learning_rate": 1.820823244552058e-05,
      "loss": 0.7028,
      "step": 7500
    },
    {
      "epoch": 9.200968523002421,
      "grad_norm": 8.48037052154541,
      "learning_rate": 1.8006456820016144e-05,
      "loss": 0.6999,
      "step": 7600
    },
    {
      "epoch": 9.322033898305085,
      "grad_norm": 3.8861050605773926,
      "learning_rate": 1.78046811945117e-05,
      "loss": 0.6976,
      "step": 7700
    },
    {
      "epoch": 9.443099273607748,
      "grad_norm": 6.141481876373291,
      "learning_rate": 1.7602905569007265e-05,
      "loss": 0.7098,
      "step": 7800
    },
    {
      "epoch": 9.564164648910412,
      "grad_norm": 6.871237754821777,
      "learning_rate": 1.7401129943502825e-05,
      "loss": 0.7245,
      "step": 7900
    },
    {
      "epoch": 9.685230024213075,
      "grad_norm": 6.997242450714111,
      "learning_rate": 1.7199354317998385e-05,
      "loss": 0.6793,
      "step": 8000
    },
    {
      "epoch": 9.806295399515738,
      "grad_norm": 6.155864715576172,
      "learning_rate": 1.699757869249395e-05,
      "loss": 0.707,
      "step": 8100
    },
    {
      "epoch": 9.927360774818402,
      "grad_norm": 8.040428161621094,
      "learning_rate": 1.6795803066989506e-05,
      "loss": 0.7383,
      "step": 8200
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.6901287553648069,
      "eval_loss": 0.7299044728279114,
      "eval_runtime": 19.6083,
      "eval_samples_per_second": 118.827,
      "eval_steps_per_second": 7.446,
      "step": 8260
    },
    {
      "epoch": 10.048426150121065,
      "grad_norm": 6.406284332275391,
      "learning_rate": 1.659402744148507e-05,
      "loss": 0.7525,
      "step": 8300
    },
    {
      "epoch": 10.169491525423728,
      "grad_norm": 5.277033805847168,
      "learning_rate": 1.639225181598063e-05,
      "loss": 0.7251,
      "step": 8400
    },
    {
      "epoch": 10.290556900726392,
      "grad_norm": 7.098425388336182,
      "learning_rate": 1.619047619047619e-05,
      "loss": 0.6833,
      "step": 8500
    },
    {
      "epoch": 10.411622276029055,
      "grad_norm": 5.101925849914551,
      "learning_rate": 1.5988700564971753e-05,
      "loss": 0.7177,
      "step": 8600
    },
    {
      "epoch": 10.532687651331718,
      "grad_norm": 4.35116720199585,
      "learning_rate": 1.5786924939467314e-05,
      "loss": 0.6868,
      "step": 8700
    },
    {
      "epoch": 10.653753026634382,
      "grad_norm": 6.211306095123291,
      "learning_rate": 1.5585149313962874e-05,
      "loss": 0.6484,
      "step": 8800
    },
    {
      "epoch": 10.774818401937045,
      "grad_norm": 5.891423225402832,
      "learning_rate": 1.5383373688458434e-05,
      "loss": 0.6726,
      "step": 8900
    },
    {
      "epoch": 10.89588377723971,
      "grad_norm": 13.860560417175293,
      "learning_rate": 1.5181598062953994e-05,
      "loss": 0.7152,
      "step": 9000
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.6935622317596567,
      "eval_loss": 0.7218305468559265,
      "eval_runtime": 17.0552,
      "eval_samples_per_second": 136.616,
      "eval_steps_per_second": 8.56,
      "step": 9086
    },
    {
      "epoch": 11.016949152542374,
      "grad_norm": 5.621758937835693,
      "learning_rate": 1.4979822437449556e-05,
      "loss": 0.7226,
      "step": 9100
    },
    {
      "epoch": 11.138014527845037,
      "grad_norm": 8.540345191955566,
      "learning_rate": 1.4778046811945116e-05,
      "loss": 0.6791,
      "step": 9200
    },
    {
      "epoch": 11.2590799031477,
      "grad_norm": 5.21412992477417,
      "learning_rate": 1.4576271186440678e-05,
      "loss": 0.688,
      "step": 9300
    },
    {
      "epoch": 11.380145278450364,
      "grad_norm": 8.563752174377441,
      "learning_rate": 1.437449556093624e-05,
      "loss": 0.6882,
      "step": 9400
    },
    {
      "epoch": 11.501210653753027,
      "grad_norm": 6.845836639404297,
      "learning_rate": 1.41727199354318e-05,
      "loss": 0.6772,
      "step": 9500
    },
    {
      "epoch": 11.62227602905569,
      "grad_norm": 6.926748752593994,
      "learning_rate": 1.397094430992736e-05,
      "loss": 0.719,
      "step": 9600
    },
    {
      "epoch": 11.743341404358354,
      "grad_norm": 6.473328590393066,
      "learning_rate": 1.3769168684422922e-05,
      "loss": 0.7053,
      "step": 9700
    },
    {
      "epoch": 11.864406779661017,
      "grad_norm": 5.42560338973999,
      "learning_rate": 1.3567393058918483e-05,
      "loss": 0.6997,
      "step": 9800
    },
    {
      "epoch": 11.98547215496368,
      "grad_norm": 5.169173240661621,
      "learning_rate": 1.3365617433414043e-05,
      "loss": 0.6852,
      "step": 9900
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.6978540772532189,
      "eval_loss": 0.7181989550590515,
      "eval_runtime": 16.9777,
      "eval_samples_per_second": 137.239,
      "eval_steps_per_second": 8.6,
      "step": 9912
    },
    {
      "epoch": 12.106537530266344,
      "grad_norm": 6.754007816314697,
      "learning_rate": 1.3165859564164648e-05,
      "loss": 0.6816,
      "step": 10000
    },
    {
      "epoch": 12.227602905569007,
      "grad_norm": 4.6906657218933105,
      "learning_rate": 1.296408393866021e-05,
      "loss": 0.6747,
      "step": 10100
    },
    {
      "epoch": 12.34866828087167,
      "grad_norm": 6.677252769470215,
      "learning_rate": 1.2762308313155772e-05,
      "loss": 0.6594,
      "step": 10200
    },
    {
      "epoch": 12.469733656174334,
      "grad_norm": 7.142979621887207,
      "learning_rate": 1.2560532687651332e-05,
      "loss": 0.6956,
      "step": 10300
    },
    {
      "epoch": 12.590799031476998,
      "grad_norm": 7.22210693359375,
      "learning_rate": 1.2358757062146894e-05,
      "loss": 0.6968,
      "step": 10400
    },
    {
      "epoch": 12.711864406779661,
      "grad_norm": 8.155708312988281,
      "learning_rate": 1.2156981436642454e-05,
      "loss": 0.6873,
      "step": 10500
    },
    {
      "epoch": 12.832929782082324,
      "grad_norm": 4.928506851196289,
      "learning_rate": 1.1955205811138014e-05,
      "loss": 0.6629,
      "step": 10600
    },
    {
      "epoch": 12.953995157384988,
      "grad_norm": 5.2838134765625,
      "learning_rate": 1.1753430185633574e-05,
      "loss": 0.7119,
      "step": 10700
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.6888412017167382,
      "eval_loss": 0.7293626666069031,
      "eval_runtime": 20.0554,
      "eval_samples_per_second": 116.178,
      "eval_steps_per_second": 7.28,
      "step": 10738
    },
    {
      "epoch": 13.075060532687651,
      "grad_norm": 6.484959125518799,
      "learning_rate": 1.1551654560129138e-05,
      "loss": 0.6995,
      "step": 10800
    },
    {
      "epoch": 13.196125907990314,
      "grad_norm": 5.070867538452148,
      "learning_rate": 1.1349878934624698e-05,
      "loss": 0.7029,
      "step": 10900
    },
    {
      "epoch": 13.317191283292978,
      "grad_norm": 7.958552837371826,
      "learning_rate": 1.1148103309120258e-05,
      "loss": 0.6486,
      "step": 11000
    },
    {
      "epoch": 13.438256658595641,
      "grad_norm": 6.081991672515869,
      "learning_rate": 1.0946327683615819e-05,
      "loss": 0.674,
      "step": 11100
    },
    {
      "epoch": 13.559322033898304,
      "grad_norm": 4.943681716918945,
      "learning_rate": 1.074455205811138e-05,
      "loss": 0.6896,
      "step": 11200
    },
    {
      "epoch": 13.680387409200968,
      "grad_norm": 7.182080268859863,
      "learning_rate": 1.054277643260694e-05,
      "loss": 0.6866,
      "step": 11300
    },
    {
      "epoch": 13.801452784503631,
      "grad_norm": 6.252495288848877,
      "learning_rate": 1.0341000807102503e-05,
      "loss": 0.6657,
      "step": 11400
    },
    {
      "epoch": 13.922518159806295,
      "grad_norm": 7.324065685272217,
      "learning_rate": 1.0139225181598063e-05,
      "loss": 0.7136,
      "step": 11500
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.6987124463519313,
      "eval_loss": 0.718934178352356,
      "eval_runtime": 19.8486,
      "eval_samples_per_second": 117.389,
      "eval_steps_per_second": 7.356,
      "step": 11564
    },
    {
      "epoch": 14.043583535108958,
      "grad_norm": 7.74993371963501,
      "learning_rate": 9.937449556093625e-06,
      "loss": 0.6866,
      "step": 11600
    },
    {
      "epoch": 14.164648910411623,
      "grad_norm": 4.014987945556641,
      "learning_rate": 9.735673930589185e-06,
      "loss": 0.695,
      "step": 11700
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 7.804690837860107,
      "learning_rate": 9.533898305084745e-06,
      "loss": 0.6687,
      "step": 11800
    },
    {
      "epoch": 14.40677966101695,
      "grad_norm": 5.131096363067627,
      "learning_rate": 9.332122679580307e-06,
      "loss": 0.6562,
      "step": 11900
    },
    {
      "epoch": 14.527845036319613,
      "grad_norm": 8.29679012298584,
      "learning_rate": 9.130347054075869e-06,
      "loss": 0.668,
      "step": 12000
    },
    {
      "epoch": 14.648910411622277,
      "grad_norm": 10.1917085647583,
      "learning_rate": 8.92857142857143e-06,
      "loss": 0.7001,
      "step": 12100
    },
    {
      "epoch": 14.76997578692494,
      "grad_norm": 3.7832489013671875,
      "learning_rate": 8.72679580306699e-06,
      "loss": 0.6576,
      "step": 12200
    },
    {
      "epoch": 14.891041162227603,
      "grad_norm": 9.60571575164795,
      "learning_rate": 8.525020177562551e-06,
      "loss": 0.6871,
      "step": 12300
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.6931330472103004,
      "eval_loss": 0.7315654158592224,
      "eval_runtime": 20.2721,
      "eval_samples_per_second": 114.936,
      "eval_steps_per_second": 7.202,
      "step": 12390
    },
    {
      "epoch": 15.012106537530267,
      "grad_norm": 12.523751258850098,
      "learning_rate": 8.323244552058112e-06,
      "loss": 0.6799,
      "step": 12400
    },
    {
      "epoch": 15.13317191283293,
      "grad_norm": 5.5713396072387695,
      "learning_rate": 8.121468926553672e-06,
      "loss": 0.674,
      "step": 12500
    },
    {
      "epoch": 15.254237288135593,
      "grad_norm": 7.9654765129089355,
      "learning_rate": 7.921711057304277e-06,
      "loss": 0.6608,
      "step": 12600
    },
    {
      "epoch": 15.375302663438257,
      "grad_norm": 6.185391902923584,
      "learning_rate": 7.719935431799839e-06,
      "loss": 0.6777,
      "step": 12700
    },
    {
      "epoch": 15.49636803874092,
      "grad_norm": 5.182826519012451,
      "learning_rate": 7.5181598062954e-06,
      "loss": 0.6412,
      "step": 12800
    },
    {
      "epoch": 15.617433414043584,
      "grad_norm": 5.90775728225708,
      "learning_rate": 7.316384180790961e-06,
      "loss": 0.6781,
      "step": 12900
    },
    {
      "epoch": 15.738498789346247,
      "grad_norm": 5.663438320159912,
      "learning_rate": 7.114608555286522e-06,
      "loss": 0.652,
      "step": 13000
    },
    {
      "epoch": 15.85956416464891,
      "grad_norm": 6.404487609863281,
      "learning_rate": 6.912832929782082e-06,
      "loss": 0.6772,
      "step": 13100
    },
    {
      "epoch": 15.980629539951574,
      "grad_norm": 4.538353443145752,
      "learning_rate": 6.711057304277643e-06,
      "loss": 0.7001,
      "step": 13200
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.7025751072961374,
      "eval_loss": 0.7199872732162476,
      "eval_runtime": 20.131,
      "eval_samples_per_second": 115.742,
      "eval_steps_per_second": 7.253,
      "step": 13216
    },
    {
      "epoch": 16.10169491525424,
      "grad_norm": 5.959500789642334,
      "learning_rate": 6.509281678773204e-06,
      "loss": 0.6601,
      "step": 13300
    },
    {
      "epoch": 16.222760290556902,
      "grad_norm": 4.873982906341553,
      "learning_rate": 6.307506053268765e-06,
      "loss": 0.6527,
      "step": 13400
    },
    {
      "epoch": 16.343825665859566,
      "grad_norm": 6.686617851257324,
      "learning_rate": 6.1057304277643255e-06,
      "loss": 0.6436,
      "step": 13500
    },
    {
      "epoch": 16.46489104116223,
      "grad_norm": 4.791067123413086,
      "learning_rate": 5.903954802259887e-06,
      "loss": 0.6897,
      "step": 13600
    },
    {
      "epoch": 16.585956416464892,
      "grad_norm": 18.955371856689453,
      "learning_rate": 5.7021791767554484e-06,
      "loss": 0.6727,
      "step": 13700
    },
    {
      "epoch": 16.707021791767556,
      "grad_norm": 4.038510799407959,
      "learning_rate": 5.500403551251009e-06,
      "loss": 0.6584,
      "step": 13800
    },
    {
      "epoch": 16.82808716707022,
      "grad_norm": 4.933835983276367,
      "learning_rate": 5.2986279257465705e-06,
      "loss": 0.6937,
      "step": 13900
    },
    {
      "epoch": 16.949152542372882,
      "grad_norm": 9.037552833557129,
      "learning_rate": 5.096852300242131e-06,
      "loss": 0.6797,
      "step": 14000
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.7021459227467811,
      "eval_loss": 0.7211561799049377,
      "eval_runtime": 20.3293,
      "eval_samples_per_second": 114.613,
      "eval_steps_per_second": 7.182,
      "step": 14042
    },
    {
      "epoch": 17.070217917675546,
      "grad_norm": 4.044398784637451,
      "learning_rate": 4.895076674737692e-06,
      "loss": 0.6394,
      "step": 14100
    },
    {
      "epoch": 17.19128329297821,
      "grad_norm": 5.4570465087890625,
      "learning_rate": 4.693301049233253e-06,
      "loss": 0.6425,
      "step": 14200
    },
    {
      "epoch": 17.312348668280872,
      "grad_norm": 7.468545913696289,
      "learning_rate": 4.491525423728814e-06,
      "loss": 0.6936,
      "step": 14300
    },
    {
      "epoch": 17.433414043583536,
      "grad_norm": 7.719503402709961,
      "learning_rate": 4.289749798224374e-06,
      "loss": 0.6508,
      "step": 14400
    },
    {
      "epoch": 17.5544794188862,
      "grad_norm": 9.494336128234863,
      "learning_rate": 4.087974172719936e-06,
      "loss": 0.7033,
      "step": 14500
    },
    {
      "epoch": 17.675544794188863,
      "grad_norm": 5.84124755859375,
      "learning_rate": 3.886198547215496e-06,
      "loss": 0.6642,
      "step": 14600
    },
    {
      "epoch": 17.796610169491526,
      "grad_norm": 7.190614223480225,
      "learning_rate": 3.6844229217110578e-06,
      "loss": 0.673,
      "step": 14700
    },
    {
      "epoch": 17.91767554479419,
      "grad_norm": 7.034181594848633,
      "learning_rate": 3.4826472962066184e-06,
      "loss": 0.636,
      "step": 14800
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.6991416309012876,
      "eval_loss": 0.7235658764839172,
      "eval_runtime": 17.8583,
      "eval_samples_per_second": 130.471,
      "eval_steps_per_second": 8.175,
      "step": 14868
    }
  ],
  "logging_steps": 100,
  "max_steps": 16520,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.382145651709542e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
