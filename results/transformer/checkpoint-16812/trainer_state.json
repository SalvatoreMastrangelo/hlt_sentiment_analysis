{
  "best_metric": 0.7101877802367141,
  "best_model_checkpoint": "./results/transformer/checkpoint-16812",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 16812,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05353319057815846,
      "grad_norm": 1.8045530319213867,
      "learning_rate": 1.6059957173447538e-06,
      "loss": 1.6212,
      "step": 100
    },
    {
      "epoch": 0.10706638115631692,
      "grad_norm": 2.5150482654571533,
      "learning_rate": 3.2119914346895077e-06,
      "loss": 1.6183,
      "step": 200
    },
    {
      "epoch": 0.16059957173447537,
      "grad_norm": 1.0449422597885132,
      "learning_rate": 4.817987152034261e-06,
      "loss": 1.6105,
      "step": 300
    },
    {
      "epoch": 0.21413276231263384,
      "grad_norm": 1.9686626195907593,
      "learning_rate": 6.423982869379015e-06,
      "loss": 1.6079,
      "step": 400
    },
    {
      "epoch": 0.2676659528907923,
      "grad_norm": 2.699831247329712,
      "learning_rate": 8.02997858672377e-06,
      "loss": 1.6076,
      "step": 500
    },
    {
      "epoch": 0.32119914346895073,
      "grad_norm": 2.125084400177002,
      "learning_rate": 9.635974304068522e-06,
      "loss": 1.6009,
      "step": 600
    },
    {
      "epoch": 0.3747323340471092,
      "grad_norm": 4.941164493560791,
      "learning_rate": 1.1241970021413277e-05,
      "loss": 1.5413,
      "step": 700
    },
    {
      "epoch": 0.4282655246252677,
      "grad_norm": 5.055100440979004,
      "learning_rate": 1.284796573875803e-05,
      "loss": 1.2334,
      "step": 800
    },
    {
      "epoch": 0.4817987152034261,
      "grad_norm": 10.722249031066895,
      "learning_rate": 1.4453961456102784e-05,
      "loss": 1.1319,
      "step": 900
    },
    {
      "epoch": 0.5353319057815846,
      "grad_norm": 3.964601993560791,
      "learning_rate": 1.605995717344754e-05,
      "loss": 1.1058,
      "step": 1000
    },
    {
      "epoch": 0.588865096359743,
      "grad_norm": 5.929845809936523,
      "learning_rate": 1.766595289079229e-05,
      "loss": 1.0173,
      "step": 1100
    },
    {
      "epoch": 0.6423982869379015,
      "grad_norm": 10.040773391723633,
      "learning_rate": 1.9271948608137044e-05,
      "loss": 1.0192,
      "step": 1200
    },
    {
      "epoch": 0.69593147751606,
      "grad_norm": 6.478682994842529,
      "learning_rate": 2.08779443254818e-05,
      "loss": 1.0024,
      "step": 1300
    },
    {
      "epoch": 0.7494646680942184,
      "grad_norm": 11.119702339172363,
      "learning_rate": 2.2483940042826554e-05,
      "loss": 0.9981,
      "step": 1400
    },
    {
      "epoch": 0.8029978586723768,
      "grad_norm": 17.706993103027344,
      "learning_rate": 2.4089935760171304e-05,
      "loss": 0.9438,
      "step": 1500
    },
    {
      "epoch": 0.8565310492505354,
      "grad_norm": 8.31670093536377,
      "learning_rate": 2.569593147751606e-05,
      "loss": 0.9348,
      "step": 1600
    },
    {
      "epoch": 0.9100642398286938,
      "grad_norm": 8.416352272033691,
      "learning_rate": 2.7301927194860815e-05,
      "loss": 0.9552,
      "step": 1700
    },
    {
      "epoch": 0.9635974304068522,
      "grad_norm": 9.908443450927734,
      "learning_rate": 2.8907922912205568e-05,
      "loss": 0.9113,
      "step": 1800
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6031318835569011,
      "eval_loss": 0.8962252736091614,
      "eval_precision": 0.6095992328607035,
      "eval_recall": 0.607623743599469,
      "eval_runtime": 64.3921,
      "eval_samples_per_second": 81.889,
      "eval_steps_per_second": 5.125,
      "step": 1868
    },
    {
      "epoch": 1.0171306209850106,
      "grad_norm": 8.337194442749023,
      "learning_rate": 2.9942897930049965e-05,
      "loss": 0.916,
      "step": 1900
    },
    {
      "epoch": 1.0706638115631693,
      "grad_norm": 7.5482001304626465,
      "learning_rate": 2.97644539614561e-05,
      "loss": 0.9243,
      "step": 2000
    },
    {
      "epoch": 1.1241970021413277,
      "grad_norm": 7.810359954833984,
      "learning_rate": 2.958600999286224e-05,
      "loss": 0.9379,
      "step": 2100
    },
    {
      "epoch": 1.177730192719486,
      "grad_norm": 10.254178047180176,
      "learning_rate": 2.940756602426838e-05,
      "loss": 0.8974,
      "step": 2200
    },
    {
      "epoch": 1.2312633832976445,
      "grad_norm": 9.620888710021973,
      "learning_rate": 2.9230906495360458e-05,
      "loss": 0.93,
      "step": 2300
    },
    {
      "epoch": 1.284796573875803,
      "grad_norm": 7.249712944030762,
      "learning_rate": 2.9052462526766594e-05,
      "loss": 0.8765,
      "step": 2400
    },
    {
      "epoch": 1.3383297644539613,
      "grad_norm": 8.758796691894531,
      "learning_rate": 2.8874018558172734e-05,
      "loss": 0.8715,
      "step": 2500
    },
    {
      "epoch": 1.39186295503212,
      "grad_norm": 13.589807510375977,
      "learning_rate": 2.8695574589578874e-05,
      "loss": 0.8576,
      "step": 2600
    },
    {
      "epoch": 1.4453961456102784,
      "grad_norm": 6.38614559173584,
      "learning_rate": 2.851713062098501e-05,
      "loss": 0.9246,
      "step": 2700
    },
    {
      "epoch": 1.4989293361884368,
      "grad_norm": 6.128326892852783,
      "learning_rate": 2.833868665239115e-05,
      "loss": 0.923,
      "step": 2800
    },
    {
      "epoch": 1.5524625267665952,
      "grad_norm": 8.250619888305664,
      "learning_rate": 2.8160242683797288e-05,
      "loss": 0.9071,
      "step": 2900
    },
    {
      "epoch": 1.6059957173447539,
      "grad_norm": 7.162379741668701,
      "learning_rate": 2.7981798715203428e-05,
      "loss": 0.8827,
      "step": 3000
    },
    {
      "epoch": 1.6595289079229123,
      "grad_norm": 11.518574714660645,
      "learning_rate": 2.7803354746609564e-05,
      "loss": 0.841,
      "step": 3100
    },
    {
      "epoch": 1.7130620985010707,
      "grad_norm": 6.235661029815674,
      "learning_rate": 2.7624910778015704e-05,
      "loss": 0.8939,
      "step": 3200
    },
    {
      "epoch": 1.7665952890792291,
      "grad_norm": 5.361471176147461,
      "learning_rate": 2.7446466809421844e-05,
      "loss": 0.8648,
      "step": 3300
    },
    {
      "epoch": 1.8201284796573876,
      "grad_norm": 16.698829650878906,
      "learning_rate": 2.726802284082798e-05,
      "loss": 0.8522,
      "step": 3400
    },
    {
      "epoch": 1.873661670235546,
      "grad_norm": 10.34887981414795,
      "learning_rate": 2.7089578872234118e-05,
      "loss": 0.8482,
      "step": 3500
    },
    {
      "epoch": 1.9271948608137044,
      "grad_norm": 7.633604526519775,
      "learning_rate": 2.6911134903640258e-05,
      "loss": 0.8345,
      "step": 3600
    },
    {
      "epoch": 1.9807280513918628,
      "grad_norm": 9.475093841552734,
      "learning_rate": 2.6732690935046398e-05,
      "loss": 0.8621,
      "step": 3700
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.6227607112939803,
      "eval_loss": 0.8490291237831116,
      "eval_precision": 0.6349748551296243,
      "eval_recall": 0.6263986345533852,
      "eval_runtime": 59.2574,
      "eval_samples_per_second": 88.985,
      "eval_steps_per_second": 5.569,
      "step": 3736
    },
    {
      "epoch": 2.0342612419700212,
      "grad_norm": 8.756360054016113,
      "learning_rate": 2.6554246966452534e-05,
      "loss": 0.8669,
      "step": 3800
    },
    {
      "epoch": 2.08779443254818,
      "grad_norm": 7.073580741882324,
      "learning_rate": 2.6375802997858674e-05,
      "loss": 0.8087,
      "step": 3900
    },
    {
      "epoch": 2.1413276231263385,
      "grad_norm": 8.128655433654785,
      "learning_rate": 2.619735902926481e-05,
      "loss": 0.8276,
      "step": 4000
    },
    {
      "epoch": 2.194860813704497,
      "grad_norm": 5.705380916595459,
      "learning_rate": 2.6018915060670948e-05,
      "loss": 0.8201,
      "step": 4100
    },
    {
      "epoch": 2.2483940042826553,
      "grad_norm": 4.8767290115356445,
      "learning_rate": 2.5840471092077088e-05,
      "loss": 0.8524,
      "step": 4200
    },
    {
      "epoch": 2.3019271948608138,
      "grad_norm": 5.40347957611084,
      "learning_rate": 2.5662027123483228e-05,
      "loss": 0.8536,
      "step": 4300
    },
    {
      "epoch": 2.355460385438972,
      "grad_norm": 6.012635707855225,
      "learning_rate": 2.5483583154889368e-05,
      "loss": 0.816,
      "step": 4400
    },
    {
      "epoch": 2.4089935760171306,
      "grad_norm": 8.977399826049805,
      "learning_rate": 2.5305139186295504e-05,
      "loss": 0.8569,
      "step": 4500
    },
    {
      "epoch": 2.462526766595289,
      "grad_norm": 5.780301570892334,
      "learning_rate": 2.512847965738758e-05,
      "loss": 0.8347,
      "step": 4600
    },
    {
      "epoch": 2.5160599571734474,
      "grad_norm": 8.228934288024902,
      "learning_rate": 2.495003568879372e-05,
      "loss": 0.8287,
      "step": 4700
    },
    {
      "epoch": 2.569593147751606,
      "grad_norm": 6.5887227058410645,
      "learning_rate": 2.4771591720199857e-05,
      "loss": 0.8396,
      "step": 4800
    },
    {
      "epoch": 2.6231263383297643,
      "grad_norm": 9.275422096252441,
      "learning_rate": 2.4593147751605997e-05,
      "loss": 0.8278,
      "step": 4900
    },
    {
      "epoch": 2.6766595289079227,
      "grad_norm": 9.648123741149902,
      "learning_rate": 2.4414703783012134e-05,
      "loss": 0.8628,
      "step": 5000
    },
    {
      "epoch": 2.730192719486081,
      "grad_norm": 7.223563194274902,
      "learning_rate": 2.4236259814418274e-05,
      "loss": 0.8253,
      "step": 5100
    },
    {
      "epoch": 2.78372591006424,
      "grad_norm": 9.779078483581543,
      "learning_rate": 2.405781584582441e-05,
      "loss": 0.8018,
      "step": 5200
    },
    {
      "epoch": 2.8372591006423984,
      "grad_norm": 5.103846549987793,
      "learning_rate": 2.387937187723055e-05,
      "loss": 0.8438,
      "step": 5300
    },
    {
      "epoch": 2.890792291220557,
      "grad_norm": 6.490381240844727,
      "learning_rate": 2.370092790863669e-05,
      "loss": 0.8361,
      "step": 5400
    },
    {
      "epoch": 2.9443254817987152,
      "grad_norm": 6.44001579284668,
      "learning_rate": 2.3522483940042827e-05,
      "loss": 0.7934,
      "step": 5500
    },
    {
      "epoch": 2.9978586723768736,
      "grad_norm": 6.766010761260986,
      "learning_rate": 2.3344039971448964e-05,
      "loss": 0.8006,
      "step": 5600
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.6577631642941564,
      "eval_loss": 0.7814357280731201,
      "eval_precision": 0.6598573442361161,
      "eval_recall": 0.657310828750237,
      "eval_runtime": 64.3493,
      "eval_samples_per_second": 81.943,
      "eval_steps_per_second": 5.128,
      "step": 5604
    },
    {
      "epoch": 3.051391862955032,
      "grad_norm": 6.0194993019104,
      "learning_rate": 2.3165596002855104e-05,
      "loss": 0.8295,
      "step": 5700
    },
    {
      "epoch": 3.1049250535331905,
      "grad_norm": 7.050354480743408,
      "learning_rate": 2.2987152034261244e-05,
      "loss": 0.7898,
      "step": 5800
    },
    {
      "epoch": 3.158458244111349,
      "grad_norm": 10.251842498779297,
      "learning_rate": 2.280870806566738e-05,
      "loss": 0.8101,
      "step": 5900
    },
    {
      "epoch": 3.2119914346895073,
      "grad_norm": 4.72646951675415,
      "learning_rate": 2.263026409707352e-05,
      "loss": 0.7994,
      "step": 6000
    },
    {
      "epoch": 3.265524625267666,
      "grad_norm": 7.452232360839844,
      "learning_rate": 2.2451820128479657e-05,
      "loss": 0.7939,
      "step": 6100
    },
    {
      "epoch": 3.3190578158458246,
      "grad_norm": 9.818622589111328,
      "learning_rate": 2.2273376159885797e-05,
      "loss": 0.7831,
      "step": 6200
    },
    {
      "epoch": 3.372591006423983,
      "grad_norm": 6.029919624328613,
      "learning_rate": 2.2094932191291934e-05,
      "loss": 0.7943,
      "step": 6300
    },
    {
      "epoch": 3.4261241970021414,
      "grad_norm": 4.432448863983154,
      "learning_rate": 2.1916488222698074e-05,
      "loss": 0.7784,
      "step": 6400
    },
    {
      "epoch": 3.4796573875803,
      "grad_norm": 5.858902454376221,
      "learning_rate": 2.1738044254104214e-05,
      "loss": 0.8442,
      "step": 6500
    },
    {
      "epoch": 3.5331905781584583,
      "grad_norm": 9.144678115844727,
      "learning_rate": 2.1561384725196287e-05,
      "loss": 0.7912,
      "step": 6600
    },
    {
      "epoch": 3.5867237687366167,
      "grad_norm": 6.587846279144287,
      "learning_rate": 2.1384725196288366e-05,
      "loss": 0.7846,
      "step": 6700
    },
    {
      "epoch": 3.640256959314775,
      "grad_norm": 6.411272048950195,
      "learning_rate": 2.1206281227694506e-05,
      "loss": 0.8265,
      "step": 6800
    },
    {
      "epoch": 3.6937901498929335,
      "grad_norm": 6.403071403503418,
      "learning_rate": 2.1027837259100643e-05,
      "loss": 0.7786,
      "step": 6900
    },
    {
      "epoch": 3.747323340471092,
      "grad_norm": 16.332275390625,
      "learning_rate": 2.084939329050678e-05,
      "loss": 0.7892,
      "step": 7000
    },
    {
      "epoch": 3.8008565310492504,
      "grad_norm": 6.83730936050415,
      "learning_rate": 2.067094932191292e-05,
      "loss": 0.7438,
      "step": 7100
    },
    {
      "epoch": 3.854389721627409,
      "grad_norm": 8.502653121948242,
      "learning_rate": 2.049250535331906e-05,
      "loss": 0.7813,
      "step": 7200
    },
    {
      "epoch": 3.907922912205567,
      "grad_norm": 6.960761547088623,
      "learning_rate": 2.0314061384725196e-05,
      "loss": 0.8064,
      "step": 7300
    },
    {
      "epoch": 3.961456102783726,
      "grad_norm": 4.448812484741211,
      "learning_rate": 2.0135617416131336e-05,
      "loss": 0.7549,
      "step": 7400
    },
    {
      "epoch": 4.0,
      "eval_f1": 0.657032916046559,
      "eval_loss": 0.7642813324928284,
      "eval_precision": 0.6589795540081979,
      "eval_recall": 0.6667930969087805,
      "eval_runtime": 59.3826,
      "eval_samples_per_second": 88.797,
      "eval_steps_per_second": 5.557,
      "step": 7472
    },
    {
      "epoch": 4.014989293361884,
      "grad_norm": 9.170668601989746,
      "learning_rate": 1.9957173447537473e-05,
      "loss": 0.7499,
      "step": 7500
    },
    {
      "epoch": 4.0685224839400425,
      "grad_norm": 9.52463150024414,
      "learning_rate": 1.9778729478943613e-05,
      "loss": 0.7665,
      "step": 7600
    },
    {
      "epoch": 4.122055674518201,
      "grad_norm": 7.758781433105469,
      "learning_rate": 1.960028551034975e-05,
      "loss": 0.7694,
      "step": 7700
    },
    {
      "epoch": 4.17558886509636,
      "grad_norm": 7.861266136169434,
      "learning_rate": 1.942184154175589e-05,
      "loss": 0.7853,
      "step": 7800
    },
    {
      "epoch": 4.229122055674519,
      "grad_norm": 6.698476791381836,
      "learning_rate": 1.924339757316203e-05,
      "loss": 0.7452,
      "step": 7900
    },
    {
      "epoch": 4.282655246252677,
      "grad_norm": 7.976954460144043,
      "learning_rate": 1.9064953604568166e-05,
      "loss": 0.7795,
      "step": 8000
    },
    {
      "epoch": 4.336188436830835,
      "grad_norm": 10.309886932373047,
      "learning_rate": 1.8886509635974303e-05,
      "loss": 0.8023,
      "step": 8100
    },
    {
      "epoch": 4.389721627408994,
      "grad_norm": 6.771804332733154,
      "learning_rate": 1.8708065667380443e-05,
      "loss": 0.7762,
      "step": 8200
    },
    {
      "epoch": 4.443254817987152,
      "grad_norm": 5.931157112121582,
      "learning_rate": 1.8529621698786583e-05,
      "loss": 0.7386,
      "step": 8300
    },
    {
      "epoch": 4.496788008565311,
      "grad_norm": 8.625043869018555,
      "learning_rate": 1.835117773019272e-05,
      "loss": 0.7625,
      "step": 8400
    },
    {
      "epoch": 4.550321199143469,
      "grad_norm": 7.549783229827881,
      "learning_rate": 1.817273376159886e-05,
      "loss": 0.7699,
      "step": 8500
    },
    {
      "epoch": 4.6038543897216275,
      "grad_norm": 6.490066051483154,
      "learning_rate": 1.7994289793004996e-05,
      "loss": 0.7493,
      "step": 8600
    },
    {
      "epoch": 4.657387580299786,
      "grad_norm": 8.447771072387695,
      "learning_rate": 1.7815845824411133e-05,
      "loss": 0.7557,
      "step": 8700
    },
    {
      "epoch": 4.710920770877944,
      "grad_norm": 9.06166934967041,
      "learning_rate": 1.7637401855817273e-05,
      "loss": 0.7237,
      "step": 8800
    },
    {
      "epoch": 4.764453961456103,
      "grad_norm": 7.413362503051758,
      "learning_rate": 1.7458957887223413e-05,
      "loss": 0.7767,
      "step": 8900
    },
    {
      "epoch": 4.817987152034261,
      "grad_norm": 6.544036388397217,
      "learning_rate": 1.7280513918629553e-05,
      "loss": 0.7784,
      "step": 9000
    },
    {
      "epoch": 4.87152034261242,
      "grad_norm": 7.496896743774414,
      "learning_rate": 1.710206995003569e-05,
      "loss": 0.7607,
      "step": 9100
    },
    {
      "epoch": 4.925053533190578,
      "grad_norm": 7.880674839019775,
      "learning_rate": 1.6923625981441826e-05,
      "loss": 0.7214,
      "step": 9200
    },
    {
      "epoch": 4.9785867237687365,
      "grad_norm": 7.053889751434326,
      "learning_rate": 1.6746966452533906e-05,
      "loss": 0.7792,
      "step": 9300
    },
    {
      "epoch": 5.0,
      "eval_f1": 0.6667603358668874,
      "eval_loss": 0.7385497093200684,
      "eval_precision": 0.6668243229382801,
      "eval_recall": 0.6711549402617106,
      "eval_runtime": 63.588,
      "eval_samples_per_second": 82.924,
      "eval_steps_per_second": 5.19,
      "step": 9340
    },
    {
      "epoch": 5.032119914346895,
      "grad_norm": 10.116427421569824,
      "learning_rate": 1.6568522483940042e-05,
      "loss": 0.7596,
      "step": 9400
    },
    {
      "epoch": 5.085653104925053,
      "grad_norm": 8.859400749206543,
      "learning_rate": 1.6390078515346182e-05,
      "loss": 0.748,
      "step": 9500
    },
    {
      "epoch": 5.139186295503212,
      "grad_norm": 6.8819451332092285,
      "learning_rate": 1.621163454675232e-05,
      "loss": 0.7327,
      "step": 9600
    },
    {
      "epoch": 5.19271948608137,
      "grad_norm": 9.78710651397705,
      "learning_rate": 1.603319057815846e-05,
      "loss": 0.7497,
      "step": 9700
    },
    {
      "epoch": 5.2462526766595285,
      "grad_norm": 8.743449211120605,
      "learning_rate": 1.58547466095646e-05,
      "loss": 0.7715,
      "step": 9800
    },
    {
      "epoch": 5.299785867237687,
      "grad_norm": 8.340839385986328,
      "learning_rate": 1.5676302640970736e-05,
      "loss": 0.7459,
      "step": 9900
    },
    {
      "epoch": 5.353319057815845,
      "grad_norm": 10.543073654174805,
      "learning_rate": 1.5497858672376876e-05,
      "loss": 0.7587,
      "step": 10000
    },
    {
      "epoch": 5.406852248394005,
      "grad_norm": 7.846472263336182,
      "learning_rate": 1.5319414703783012e-05,
      "loss": 0.7516,
      "step": 10100
    },
    {
      "epoch": 5.460385438972163,
      "grad_norm": 8.146581649780273,
      "learning_rate": 1.514097073518915e-05,
      "loss": 0.703,
      "step": 10200
    },
    {
      "epoch": 5.5139186295503215,
      "grad_norm": 15.32889175415039,
      "learning_rate": 1.4962526766595289e-05,
      "loss": 0.7121,
      "step": 10300
    },
    {
      "epoch": 5.56745182012848,
      "grad_norm": 6.989447116851807,
      "learning_rate": 1.4784082798001427e-05,
      "loss": 0.724,
      "step": 10400
    },
    {
      "epoch": 5.620985010706638,
      "grad_norm": 6.007458686828613,
      "learning_rate": 1.4605638829407567e-05,
      "loss": 0.7135,
      "step": 10500
    },
    {
      "epoch": 5.674518201284797,
      "grad_norm": 8.345242500305176,
      "learning_rate": 1.4427194860813706e-05,
      "loss": 0.7657,
      "step": 10600
    },
    {
      "epoch": 5.728051391862955,
      "grad_norm": 5.803915500640869,
      "learning_rate": 1.4248750892219842e-05,
      "loss": 0.7151,
      "step": 10700
    },
    {
      "epoch": 5.781584582441114,
      "grad_norm": 15.752507209777832,
      "learning_rate": 1.4070306923625982e-05,
      "loss": 0.745,
      "step": 10800
    },
    {
      "epoch": 5.835117773019272,
      "grad_norm": 9.526016235351562,
      "learning_rate": 1.389186295503212e-05,
      "loss": 0.7527,
      "step": 10900
    },
    {
      "epoch": 5.8886509635974305,
      "grad_norm": 15.786361694335938,
      "learning_rate": 1.3713418986438257e-05,
      "loss": 0.7526,
      "step": 11000
    },
    {
      "epoch": 5.942184154175589,
      "grad_norm": 6.55833625793457,
      "learning_rate": 1.3534975017844397e-05,
      "loss": 0.7344,
      "step": 11100
    },
    {
      "epoch": 5.995717344753747,
      "grad_norm": 5.949221611022949,
      "learning_rate": 1.3356531049250536e-05,
      "loss": 0.6963,
      "step": 11200
    },
    {
      "epoch": 6.0,
      "eval_f1": 0.6955192841929413,
      "eval_loss": 0.708457887172699,
      "eval_precision": 0.6949678096748549,
      "eval_recall": 0.6980845818319742,
      "eval_runtime": 65.6562,
      "eval_samples_per_second": 80.312,
      "eval_steps_per_second": 5.026,
      "step": 11208
    },
    {
      "epoch": 6.049250535331906,
      "grad_norm": 10.089736938476562,
      "learning_rate": 1.3179871520342614e-05,
      "loss": 0.7444,
      "step": 11300
    },
    {
      "epoch": 6.102783725910064,
      "grad_norm": 6.704277515411377,
      "learning_rate": 1.300142755174875e-05,
      "loss": 0.7237,
      "step": 11400
    },
    {
      "epoch": 6.1563169164882225,
      "grad_norm": 8.674209594726562,
      "learning_rate": 1.282298358315489e-05,
      "loss": 0.7009,
      "step": 11500
    },
    {
      "epoch": 6.209850107066381,
      "grad_norm": 13.613154411315918,
      "learning_rate": 1.2644539614561029e-05,
      "loss": 0.6891,
      "step": 11600
    },
    {
      "epoch": 6.263383297644539,
      "grad_norm": 7.928559303283691,
      "learning_rate": 1.2466095645967165e-05,
      "loss": 0.7417,
      "step": 11700
    },
    {
      "epoch": 6.316916488222698,
      "grad_norm": 11.023387908935547,
      "learning_rate": 1.2287651677373305e-05,
      "loss": 0.7524,
      "step": 11800
    },
    {
      "epoch": 6.370449678800856,
      "grad_norm": 12.117097854614258,
      "learning_rate": 1.2109207708779444e-05,
      "loss": 0.7446,
      "step": 11900
    },
    {
      "epoch": 6.423982869379015,
      "grad_norm": 9.158214569091797,
      "learning_rate": 1.1930763740185582e-05,
      "loss": 0.7375,
      "step": 12000
    },
    {
      "epoch": 6.477516059957173,
      "grad_norm": 5.841573238372803,
      "learning_rate": 1.175231977159172e-05,
      "loss": 0.7284,
      "step": 12100
    },
    {
      "epoch": 6.531049250535332,
      "grad_norm": 8.823124885559082,
      "learning_rate": 1.1573875802997859e-05,
      "loss": 0.7192,
      "step": 12200
    },
    {
      "epoch": 6.58458244111349,
      "grad_norm": 11.347171783447266,
      "learning_rate": 1.1395431834403999e-05,
      "loss": 0.7436,
      "step": 12300
    },
    {
      "epoch": 6.638115631691649,
      "grad_norm": 8.241667747497559,
      "learning_rate": 1.1216987865810135e-05,
      "loss": 0.6977,
      "step": 12400
    },
    {
      "epoch": 6.691648822269808,
      "grad_norm": 10.27375316619873,
      "learning_rate": 1.1038543897216274e-05,
      "loss": 0.7228,
      "step": 12500
    },
    {
      "epoch": 6.745182012847966,
      "grad_norm": 10.65898323059082,
      "learning_rate": 1.0860099928622414e-05,
      "loss": 0.7175,
      "step": 12600
    },
    {
      "epoch": 6.7987152034261245,
      "grad_norm": 8.041152954101562,
      "learning_rate": 1.0681655960028552e-05,
      "loss": 0.722,
      "step": 12700
    },
    {
      "epoch": 6.852248394004283,
      "grad_norm": 9.869233131408691,
      "learning_rate": 1.0503211991434688e-05,
      "loss": 0.7134,
      "step": 12800
    },
    {
      "epoch": 6.905781584582441,
      "grad_norm": 14.844520568847656,
      "learning_rate": 1.0324768022840828e-05,
      "loss": 0.7341,
      "step": 12900
    },
    {
      "epoch": 6.9593147751606,
      "grad_norm": 9.622618675231934,
      "learning_rate": 1.0146324054246967e-05,
      "loss": 0.7108,
      "step": 13000
    },
    {
      "epoch": 7.0,
      "eval_f1": 0.7052545670599594,
      "eval_loss": 0.6865969896316528,
      "eval_precision": 0.7044085063922492,
      "eval_recall": 0.707187559264176,
      "eval_runtime": 60.9936,
      "eval_samples_per_second": 86.452,
      "eval_steps_per_second": 5.41,
      "step": 13076
    },
    {
      "epoch": 7.012847965738758,
      "grad_norm": 8.836418151855469,
      "learning_rate": 9.967880085653105e-06,
      "loss": 0.7212,
      "step": 13100
    },
    {
      "epoch": 7.0663811563169165,
      "grad_norm": 9.301426887512207,
      "learning_rate": 9.789436117059243e-06,
      "loss": 0.7014,
      "step": 13200
    },
    {
      "epoch": 7.119914346895075,
      "grad_norm": 5.136137008666992,
      "learning_rate": 9.610992148465382e-06,
      "loss": 0.7129,
      "step": 13300
    },
    {
      "epoch": 7.173447537473233,
      "grad_norm": 9.001344680786133,
      "learning_rate": 9.43433261955746e-06,
      "loss": 0.68,
      "step": 13400
    },
    {
      "epoch": 7.226980728051392,
      "grad_norm": 9.528022766113281,
      "learning_rate": 9.255888650963596e-06,
      "loss": 0.7145,
      "step": 13500
    },
    {
      "epoch": 7.28051391862955,
      "grad_norm": 8.11666488647461,
      "learning_rate": 9.077444682369736e-06,
      "loss": 0.7392,
      "step": 13600
    },
    {
      "epoch": 7.334047109207709,
      "grad_norm": 8.628121376037598,
      "learning_rate": 8.899000713775875e-06,
      "loss": 0.6776,
      "step": 13700
    },
    {
      "epoch": 7.387580299785867,
      "grad_norm": 7.925573348999023,
      "learning_rate": 8.720556745182013e-06,
      "loss": 0.712,
      "step": 13800
    },
    {
      "epoch": 7.4411134903640255,
      "grad_norm": 15.938607215881348,
      "learning_rate": 8.542112776588151e-06,
      "loss": 0.6919,
      "step": 13900
    },
    {
      "epoch": 7.494646680942184,
      "grad_norm": 11.760764122009277,
      "learning_rate": 8.36366880799429e-06,
      "loss": 0.7066,
      "step": 14000
    },
    {
      "epoch": 7.548179871520342,
      "grad_norm": 8.53817081451416,
      "learning_rate": 8.18522483940043e-06,
      "loss": 0.7331,
      "step": 14100
    },
    {
      "epoch": 7.601713062098501,
      "grad_norm": 7.448978424072266,
      "learning_rate": 8.006780870806566e-06,
      "loss": 0.7152,
      "step": 14200
    },
    {
      "epoch": 7.655246252676659,
      "grad_norm": 6.142787933349609,
      "learning_rate": 7.828336902212705e-06,
      "loss": 0.717,
      "step": 14300
    },
    {
      "epoch": 7.708779443254818,
      "grad_norm": 7.8270649909973145,
      "learning_rate": 7.649892933618845e-06,
      "loss": 0.7472,
      "step": 14400
    },
    {
      "epoch": 7.762312633832977,
      "grad_norm": 6.925686836242676,
      "learning_rate": 7.471448965024982e-06,
      "loss": 0.7248,
      "step": 14500
    },
    {
      "epoch": 7.815845824411135,
      "grad_norm": 7.780067443847656,
      "learning_rate": 7.293004996431121e-06,
      "loss": 0.6915,
      "step": 14600
    },
    {
      "epoch": 7.869379014989294,
      "grad_norm": 8.981525421142578,
      "learning_rate": 7.114561027837259e-06,
      "loss": 0.7335,
      "step": 14700
    },
    {
      "epoch": 7.922912205567452,
      "grad_norm": 15.298166275024414,
      "learning_rate": 6.936117059243397e-06,
      "loss": 0.7292,
      "step": 14800
    },
    {
      "epoch": 7.9764453961456105,
      "grad_norm": 4.14316987991333,
      "learning_rate": 6.757673090649536e-06,
      "loss": 0.7016,
      "step": 14900
    },
    {
      "epoch": 8.0,
      "eval_f1": 0.7073487080228679,
      "eval_loss": 0.6786054968833923,
      "eval_precision": 0.7066525361898915,
      "eval_recall": 0.7090840128958847,
      "eval_runtime": 65.4909,
      "eval_samples_per_second": 80.515,
      "eval_steps_per_second": 5.039,
      "step": 14944
    },
    {
      "epoch": 8.029978586723768,
      "grad_norm": 8.305377960205078,
      "learning_rate": 6.579229122055675e-06,
      "loss": 0.6833,
      "step": 15000
    },
    {
      "epoch": 8.083511777301927,
      "grad_norm": 9.263233184814453,
      "learning_rate": 6.400785153461813e-06,
      "loss": 0.6848,
      "step": 15100
    },
    {
      "epoch": 8.137044967880085,
      "grad_norm": 6.209698677062988,
      "learning_rate": 6.222341184867951e-06,
      "loss": 0.7428,
      "step": 15200
    },
    {
      "epoch": 8.190578158458244,
      "grad_norm": 8.292479515075684,
      "learning_rate": 6.0438972162740905e-06,
      "loss": 0.671,
      "step": 15300
    },
    {
      "epoch": 8.244111349036402,
      "grad_norm": 10.849594116210938,
      "learning_rate": 5.867237687366167e-06,
      "loss": 0.6616,
      "step": 15400
    },
    {
      "epoch": 8.297644539614561,
      "grad_norm": 10.265731811523438,
      "learning_rate": 5.688793718772305e-06,
      "loss": 0.6634,
      "step": 15500
    },
    {
      "epoch": 8.35117773019272,
      "grad_norm": 11.528162002563477,
      "learning_rate": 5.510349750178444e-06,
      "loss": 0.7097,
      "step": 15600
    },
    {
      "epoch": 8.404710920770878,
      "grad_norm": 5.461300373077393,
      "learning_rate": 5.331905781584583e-06,
      "loss": 0.6825,
      "step": 15700
    },
    {
      "epoch": 8.458244111349037,
      "grad_norm": 9.617047309875488,
      "learning_rate": 5.153461812990721e-06,
      "loss": 0.6823,
      "step": 15800
    },
    {
      "epoch": 8.511777301927195,
      "grad_norm": 15.763177871704102,
      "learning_rate": 4.975017844396859e-06,
      "loss": 0.7177,
      "step": 15900
    },
    {
      "epoch": 8.565310492505354,
      "grad_norm": 8.48340892791748,
      "learning_rate": 4.796573875802998e-06,
      "loss": 0.7062,
      "step": 16000
    },
    {
      "epoch": 8.618843683083512,
      "grad_norm": 12.518735885620117,
      "learning_rate": 4.618129907209137e-06,
      "loss": 0.6879,
      "step": 16100
    },
    {
      "epoch": 8.67237687366167,
      "grad_norm": 8.52440357208252,
      "learning_rate": 4.439685938615275e-06,
      "loss": 0.7074,
      "step": 16200
    },
    {
      "epoch": 8.725910064239828,
      "grad_norm": 15.025724411010742,
      "learning_rate": 4.261241970021413e-06,
      "loss": 0.6651,
      "step": 16300
    },
    {
      "epoch": 8.779443254817988,
      "grad_norm": 6.6969194412231445,
      "learning_rate": 4.082798001427552e-06,
      "loss": 0.7186,
      "step": 16400
    },
    {
      "epoch": 8.832976445396145,
      "grad_norm": 5.497759819030762,
      "learning_rate": 3.90435403283369e-06,
      "loss": 0.706,
      "step": 16500
    },
    {
      "epoch": 8.886509635974305,
      "grad_norm": 4.638975143432617,
      "learning_rate": 3.7259100642398288e-06,
      "loss": 0.6664,
      "step": 16600
    },
    {
      "epoch": 8.940042826552462,
      "grad_norm": 6.24315071105957,
      "learning_rate": 3.5474660956459675e-06,
      "loss": 0.7277,
      "step": 16700
    },
    {
      "epoch": 8.993576017130621,
      "grad_norm": 7.619500637054443,
      "learning_rate": 3.3690221270521054e-06,
      "loss": 0.7174,
      "step": 16800
    },
    {
      "epoch": 9.0,
      "eval_f1": 0.7101877802367141,
      "eval_loss": 0.6710872650146484,
      "eval_precision": 0.7098457096159334,
      "eval_recall": 0.7121183387066187,
      "eval_runtime": 62.0012,
      "eval_samples_per_second": 85.047,
      "eval_steps_per_second": 5.322,
      "step": 16812
    }
  ],
  "logging_steps": 100,
  "max_steps": 18680,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.220883926646374e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
