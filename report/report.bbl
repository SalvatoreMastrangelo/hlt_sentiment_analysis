\begin{thebibliography}{16}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cahuantzi et~al.(2023)Cahuantzi, Chen, and Güttel]{Cahuantzi_2023}
Roberto Cahuantzi, Xinye Chen, and Stefan Güttel.
\newblock A comparison of lstm and gru networks for learning symbolic sequences, 2023.
\newblock ISSN 2367-3389.
\newblock URL \url{http://dx.doi.org/10.1007/978-3-031-37963-5_53}.

\bibitem[Cho et~al.(2014)Cho, van Merrienboer, Bahdanau, and Bengio]{cho2014learning}
Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua Bengio.
\newblock On the properties of neural machine translation: Encoder-decoder approaches, 2014.
\newblock URL \url{https://arxiv.org/abs/1409.1259}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding, 2019.
\newblock URL \url{https://arxiv.org/abs/1810.04805}.

\bibitem[Ganai and Khursheed(2019)]{ganai2019predicting}
Aejaz~Farooq Ganai and Farida Khursheed.
\newblock Predicting next word using rnn and lstm cells: Stastical language modeling.
\newblock In \emph{2019 fifth international conference on image information processing (ICIIP)}, pages 469--474. IEEE, 2019.

\bibitem[Gupta et~al.(2024)Gupta, Ranjan, and Singh]{gupta2024comprehensivestudysentimentanalysis}
Shailja Gupta, Rajesh Ranjan, and Surya~Narayan Singh.
\newblock Comprehensive study on sentiment analysis: From rule-based to modern llm based system, 2024.
\newblock URL \url{https://arxiv.org/abs/2409.09989}.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory, 1997.

\bibitem[Husein et~al.(2023)Husein, Livando, Andika, Chandra, and Phan]{husein2023sentiment}
Amir~Mahmud Husein, Nicholas Livando, Andika Andika, William Chandra, and Gary Phan.
\newblock Sentiment analysis of hotel reviews on tripadvisor with lstm and electra.
\newblock \emph{Sinkron: jurnal dan penelitian teknik informatika}, 7\penalty0 (2):\penalty0 733--740, 2023.

\bibitem[Kalra and Barkeshli(2024)]{kalra2024warmuplearningrateunderlying}
Dayal~Singh Kalra and Maissam Barkeshli.
\newblock Why warmup the learning rate? underlying mechanisms and improvements, 2024.
\newblock URL \url{https://arxiv.org/abs/2406.09405}.

\bibitem[Kingma and Ba(2017)]{kingma2017adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization, 2017.
\newblock URL \url{https://arxiv.org/abs/1412.6980}.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov]{liu2019robertarobustlyoptimizedbert}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach, 2019.
\newblock URL \url{https://arxiv.org/abs/1907.11692}.

\bibitem[Loshchilov and Hutter(2019)]{loshchilov2019decoupledweightdecayregularization}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization, 2019.
\newblock URL \url{https://arxiv.org/abs/1711.05101}.

\bibitem[Staudemeyer and Morris(2019)]{staudemeyer2019understandinglstmtutorial}
Ralf~C. Staudemeyer and Eric~Rothstein Morris.
\newblock Understanding lstm -- a tutorial into long short-term memory recurrent neural networks, 2019.
\newblock URL \url{https://arxiv.org/abs/1909.09586}.

\bibitem[Torrey and Shavlik(2010)]{torrey2010transfer}
Lisa Torrey and Jude Shavlik.
\newblock Transfer learning.
\newblock In \emph{Handbook of research on machine learning applications and trends: algorithms, methods, and techniques}, pages 242--264. IGI global, 2010.

\bibitem[Vaswani et~al.(2023)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2023attentionneed}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need, 2023.
\newblock URL \url{https://arxiv.org/abs/1706.03762}.

\bibitem[Wen et~al.(2023)Wen, Liang, and Zhu]{wen2023sentiment}
Yu~Wen, Yezhang Liang, and Xinhua Zhu.
\newblock Sentiment analysis of hotel online reviews using the bert model and ernie model—data from china.
\newblock \emph{Plos one}, 18\penalty0 (3):\penalty0 e0275382, 2023.

\bibitem[Zhang et~al.(2019)Zhang, Han, Liu, Jiang, Sun, and Liu]{zhang2019ernieenhancedlanguagerepresentation}
Zhengyan Zhang, Xu~Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, and Qun Liu.
\newblock Ernie: Enhanced language representation with informative entities, 2019.
\newblock URL \url{https://arxiv.org/abs/1905.07129}.

\end{thebibliography}
